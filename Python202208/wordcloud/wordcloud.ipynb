{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "181c793c-542f-4cd6-a32a-852763bae27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x7fbea82f8e20>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wordcloud\n",
    "\n",
    "# 从外部.txt文件中读取大段文本，存入变量txt中\n",
    "f = open('wenben.txt',encoding='utf-8')\n",
    "txt = f.read()\n",
    "\n",
    "# 构建词云对象w，设置词云图片宽、高、字体、背景颜色等参数\n",
    "w = wordcloud.WordCloud(width=1000,\n",
    "                        height=700,\n",
    "                        background_color='white',\n",
    "                        font_path='STHeiti Light.ttc')\n",
    "\n",
    "# 将txt变量传入w的generate()方法，给词云输入文字\n",
    "w.generate(txt)\n",
    "\n",
    "# 将词云图片导出到当前文件夹\n",
    "w.to_file('./output_pic/result1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e14c4439-37f0-4e5b-81ba-bbbef6005435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/39/5qbjzw7j1z3d6_s1t0hy1d9h0000gn/T/jieba.cache\n",
      "Loading model cost 0.390 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x7fbea8699880>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "import wordcloud\n",
    "\n",
    "# 构建并配置词云对象w\n",
    "w = wordcloud.WordCloud(width=1000,\n",
    "                        height=700,\n",
    "                        background_color='white',\n",
    "                        font_path='STHeiti Light.ttc')\n",
    "\n",
    "# 对来自外部文件的文本进行中文分词，得到string\n",
    "f = open('wenben.txt',encoding='utf-8')\n",
    "txt = f.read()\n",
    "txtlist = jieba.lcut(txt)\n",
    "string = \" \".join(txtlist)\n",
    "\n",
    "# 将string变量传入w的generate()方法，给词云输入文字\n",
    "w.generate(string)\n",
    "\n",
    "# 将词云图片导出到当前文件夹\n",
    "w.to_file('./output_pic/result2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7683df-04d4-4c8c-8ee6-7b2224180f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x7fbea8304c40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入词云制作库wordcloud和中文分词库jieba\n",
    "import jieba\n",
    "import wordcloud\n",
    "\n",
    "# 导入imageio库中的imread函数，并用这个函数读取本地图片，作为词云形状图片\n",
    "import imageio\n",
    "mk = imageio.imread(\"./input_pic/chinamap.png\")\n",
    "\n",
    "# 构建并配置词云对象w，注意要加stopwords集合参数，将不想展示在词云中的词放在stopwords集合里，这里去掉“曹操”和“孔明”两个词\n",
    "w = wordcloud.WordCloud(width=1000,\n",
    "                        height=700,\n",
    "                        background_color='white',\n",
    "                        font_path='STHeiti Light.ttc',\n",
    "                        mask=mk,\n",
    "                        scale=15,\n",
    "                        stopwords={'曹操','孔明'})\n",
    "\n",
    "# 对来自外部文件的文本进行中文分词，得到string\n",
    "f = open('wenben.txt',encoding='utf-8')\n",
    "txt = f.read()\n",
    "txtlist = jieba.lcut(txt)\n",
    "string = \" \".join(txtlist)\n",
    "\n",
    "# 将string变量传入w的generate()方法，给词云输入文字\n",
    "w.generate(string)\n",
    "\n",
    "# 将词云图片导出到当前文件夹\n",
    "w.to_file('./output_pic/result3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50570332-4eb3-4bcb-8207-5f98d7bede2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x7fbea82f8460>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入词云制作库wordcloud和中文分词库jieba\n",
    "import jieba\n",
    "import wordcloud\n",
    "\n",
    "# 导入imageio库中的imread函数，并用这个函数读取本地图片，作为词云形状图片\n",
    "import imageio\n",
    "mk = imageio.imread(\"./input_pic/chinamap.png\")\n",
    "\n",
    "\n",
    "# 构建并配置词云对象w，注意要加stopwords集合参数，将不想展示在词云中的词放在stopwords集合里，这里去掉“曹操”和“孔明”两个词\n",
    "w = wordcloud.WordCloud(width=1000,\n",
    "                        height=700,\n",
    "                        background_color='white',\n",
    "                        font_path='STHeiti Light.ttc',\n",
    "                        mask=mk,\n",
    "                        scale=15,\n",
    "                        stopwords={'的','和','应当','或者'})\n",
    "\n",
    "# 对来自外部文件的文本进行中文分词，得到string\n",
    "f = open('wenben.txt',encoding='utf-8')\n",
    "txt = f.read()\n",
    "txtlist = jieba.lcut(txt)\n",
    "string = \" \".join(txtlist)\n",
    "\n",
    "# 将string变量传入w的generate()方法，给词云输入文字\n",
    "w.generate(string)\n",
    "\n",
    "# 将词云图片导出到当前文件夹\n",
    "w.to_file('./output_pic/result4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b92bd636-83c3-45ba-9fc3-da29d9dcf297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x7fbeba519100>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入词云制作库wordcloud和中文分词库jieba\n",
    "import jieba\n",
    "import wordcloud\n",
    "\n",
    "# 导入imageio库中的imread函数，并用这个函数读取本地图片，作为词云形状图片\n",
    "import imageio\n",
    "mk = imageio.imread(\"./input_pic/chinamap.png\")\n",
    "\n",
    "\n",
    "# new add stopwords\n",
    "stopwords = set()\n",
    "content = [line.strip() for line in open('cn_stopwords.txt','r').readlines()]\n",
    "stopwords.update(content)\n",
    "stopwords.add('应当')\n",
    "\n",
    "\n",
    "# 构建并配置词云对象w，注意要加stopwords集合参数，将不想展示在词云中的词放在stopwords集合里，这里去掉“曹操”和“孔明”两个词\n",
    "w = wordcloud.WordCloud(width=1000,\n",
    "                        height=700,\n",
    "                        background_color='white',\n",
    "                        font_path='STHeiti Light.ttc',\n",
    "                        mask=mk,\n",
    "                        scale=15,\n",
    "                        stopwords=stopwords)\n",
    "\n",
    "# 对来自外部文件的文本进行中文分词，得到string\n",
    "f = open('wenben.txt',encoding='utf-8')\n",
    "txt = f.read()\n",
    "txtlist = jieba.lcut(txt)\n",
    "string = \" \".join(txtlist)\n",
    "\n",
    "# 将string变量传入w的generate()方法，给词云输入文字\n",
    "w.generate(string)\n",
    "\n",
    "# 将词云图片导出到当前文件夹\n",
    "w.to_file('./output_pic/result5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57edd382-404c-4a64-b1cc-49ba6a23077c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8e1209-68fd-4a1a-be89-936de7d79d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://amueller.github.io/word_cloud/index.html\n",
    "# 如需超高清的，可以to_svg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
